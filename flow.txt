1. read the input. for each line, eliminate patterns. then, reduce the text field to contain text only.
output: <year, <text, multiplier> >, eliminate lines that are from irrelevant years

2. read the input. for each line, breakdown into pairs. each pair that contains a stop-word will be eliminated, and those
that don't will be written to context: <year, < <w1, w2>, #appearences> >

3. count the pairs and single words

4. calculate PMI for each pair

5. find the best K PMIs

6. calculate the F-Measure for those K pairs, per decade


***Types***
1. <text, text>
2. <long, long>
3. <<text, text>, longwritable>
4. <<text, text>, <longwritable, longwritable>>


==========================================================
               open questions for majeek
==========================================================

1. If a stop word is the middle word, are all generated pairs discarded?
2. Do we need to take into account the number of instances of each nGram, or do we count it as one either way?
3. In regards to counting occurrences of single words, do we count before we discard stop words or after?
4.